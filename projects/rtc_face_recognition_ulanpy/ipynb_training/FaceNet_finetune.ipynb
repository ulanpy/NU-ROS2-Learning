{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e3a1c1-d2e9-4666-be34-7c6d1d320c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in /home/ulan/anaconda3/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in /home/ulan/anaconda3/lib/python3.11/site-packages (from mtcnn) (3.4.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in /home/ulan/anaconda3/lib/python3.11/site-packages (from mtcnn) (4.8.0.76)\n",
      "Requirement already satisfied: absl-py in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (1.26.4)\n",
      "Requirement already satisfied: rich in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (3.11.0)\n",
      "Requirement already satisfied: optree in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (0.4.0)\n",
      "Requirement already satisfied: packaging in /home/ulan/anaconda3/lib/python3.11/site-packages (from keras>=2.0.0->mtcnn) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ulan/anaconda3/lib/python3.11/site-packages (from optree->keras>=2.0.0->mtcnn) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ulan/anaconda3/lib/python3.11/site-packages (from rich->keras>=2.0.0->mtcnn) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ulan/anaconda3/lib/python3.11/site-packages (from rich->keras>=2.0.0->mtcnn) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ulan/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca98e99-f8b1-4064-a8ca-26968e680f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 18:56:35.835421: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-25 18:56:35.946773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-25 18:56:35.993811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-25 18:56:36.006897: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-25 18:56:36.088450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-25 18:56:37.042160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv \n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559764b6-84c4-490d-8252-416a5210c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2.904] global loadsave.cpp:248 findDecoder imread_('dataset/person1/picture1.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread(\"dataset/person1/picture1.jpg\")\n",
    "#opencv read BGR channel format and plt reads images as RGB channel format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7e51e0-d299-4137-85b8-87ff98e2fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735134999.077223    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.233590    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.233655    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.237525    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.237577    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.237598    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.647424    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1735134999.647500    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-25 18:56:39.647509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1735134999.647544    2135 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-25 18:56:39.647882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "ename": "InvalidImage",
     "evalue": "Image not valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidImage\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m detector \u001b[38;5;241m=\u001b[39m MTCNN()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#mtcnn is RGB channel mode \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect_faces(img)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mtcnn/mtcnn.py:285\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03mDetects bounding boxes from the specified image.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m:param img: image to process\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m:return: list containing all the bounding boxes detected with their keypoints.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidImage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    288\u001b[0m stage_status \u001b[38;5;241m=\u001b[39m StageStatus(width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight)\n",
      "\u001b[0;31mInvalidImage\u001b[0m: Image not valid."
     ]
    }
   ],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "detector = MTCNN()\n",
    "#mtcnn is RGB channel mode \n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "results = detector.detect_faces(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a6680-61f6-449a-a43a-d706466d848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "\n",
    "# For now we only need 'box' value here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2104f-3bdd-4743-8261-e567092bdfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = results[0]['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae536521-76f3-4f86-9ab5-3324211cb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.rectangle(img, pt1=(x,y), pt2=(x+w, y+h), color=(0,0,255), thickness=5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061d48e-eae6-4633-8f6b-6885a2893a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_face = img[y:y+h, x:x+w]\n",
    "plt.imshow(my_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624c499-f782-4a12-8386-d41e136686d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize it for FaseNet bc it takes as input 160x160 size image \n",
    "my_face = cv.resize(my_face, (160,160))\n",
    "plt.imshow(my_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c29c8-ed3a-405b-922e-791d584aab32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13452047-a132-4101-9b5a-667ab3bc752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18727b4a-3428-4df3-8e8e-6123bc105b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now time to automate this process \n",
    "class FACELOADING:\n",
    "\n",
    "    def __init__(self, directory: str) -> None:\n",
    "        self.directory = directory\n",
    "        self.target_size = (160, 160)\n",
    "        self.X = [] # all images in X array \n",
    "        self.Y = [] # all labels in Y array \n",
    "        self.detector = MTCNN()\n",
    "\n",
    "    # handle every image \n",
    "    def extract_face(self, filename: str) -> np.ndarray:\n",
    "        img = cv.imread(filename)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        x,y,w,h = detector.detect_faces(img)[0]['box']\n",
    "        x, y = abs(x), abs(y) # for debugging purposes\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face_arr = cv.resize(face, self.target_size)\n",
    "        return face_arr\n",
    "\n",
    "    \n",
    "    def load_faces(self, dir:str) -> list:\n",
    "        FACES = []\n",
    "        for im_name in os.listdir(dir):\n",
    "            try:\n",
    "                path = dir + im_name\n",
    "                single_face = self.extract_face(filename=path)\n",
    "                FACES.append(single_face)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        return FACES\n",
    "\n",
    "\n",
    "    def load_classes(self):\n",
    "        for sub_dir in os.listdir(self.directory):\n",
    "            path = self.directory + '/' + sub_dir + '/'\n",
    "            FACES = self.load_faces(path)\n",
    "            labels = [sub_dir for _ in range(len(FACES))]\n",
    "            print(f\"loaded successfully: {len(labels)}\")\n",
    "            self.X.extend(FACES) # here we use extend() method because append add all FACE list as a single element which is not we want\n",
    "            self.Y.extend(labels)\n",
    "        return np.asarray(self.X), np.asarray(self.Y)\n",
    "\n",
    "\n",
    "    def plot_images(self):\n",
    "        plt.figure(figsize=(16,12))\n",
    "        for num, image in enumerate(self.X):\n",
    "            ncols = 3 \n",
    "            nrows = len(self.Y)//ncols + 2\n",
    "            plt.subplot(nrows, ncols, num+1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4052f-66af-47ec-86f7-d306420b3eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faceloading = FACELOADING(\"dataset\")\n",
    "X , Y = faceloading.load_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79922f9b-7316-4f0a-9f01-150aa333c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceloading.plot_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f455ee-d219-4b9b-b66a-20f28b5589ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install keras-facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a41eb-a172-443d-b389-aa5784152d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_facenet import FaceNet\n",
    "\n",
    "embedder = FaceNet()\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    face_img = face_img.astype('float32') # 3D tensor (160 x 160 x 3)\n",
    "    face_img = np.expand_dims(face_img, axis=0)  # tensorflow requires 4 dimensions (None x 160 x 160 x 3)\n",
    "    yhat = embedder.embeddings(face_img)\n",
    "    return yhat[0] # 512D image (1x1x512)\n",
    "    yhat[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a77dd2-39f7-499b-a183-7d842be32c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDED_X = []\n",
    "\n",
    "for img in X:\n",
    "    EMBEDDED_X.append(get_embedding(img))\n",
    "\n",
    "EMBEDDED_X = np.asarray(EMBEDDED_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c073697-77b3-474e-a5ae-b6a609175a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('faces.npz', EMBEDDED_X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf3300-5e82-457c-97fc-c70e2838a5f0",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fcbbc-72f3-49f9-b269-b595fa105f1d",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) work on the principle of finding an optimal hyperplane that best separates the data points from different classes in a high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab11205-c8f0-4dc6-b8e0-f01ab6e14530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9c102-5a19-41af-9868-f85697edfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(EMBEDDED_X, Y, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacb027-decd-409a-a6f1-fbc640c2b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "# start with \"linear kernel\" and test on confusion matrix number of false positives, if SVM is underperforming switch kernel to \"RBF\" \n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d35c8-c04b-49bb-888f-e09830be8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds_train = model.predict(X_train)\n",
    "ypreds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e842280-bbdb-4fdc-a3a7-0ed9999f3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Y_train, ypreds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0136a-a570-48ef-b84d-9b23dfb9dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, ypreds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f0ced-2b36-4ea4-9874-510b0a5a6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"svm.pkl\", 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb0e8c-6edb-42eb-a109-24be49c5a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"svm.pkl\", 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
